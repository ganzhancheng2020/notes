##贝叶斯定理

贝叶斯公式：  
>P（A|B）= P(B|A)*P(A)/P(B)
  
设A,B是两个事件
先验概率：P(A) 即在B事件发生之前，我们对A事件概率的一个判断
后验概率：P(A|B) 即在B事件发生后，A发生的概率。

例：垃圾邮件分类
设：有400封邮件，300封是正常邮件其中有3封是带有发票，100封是垃圾邮件其中5封是带发票。  
问：当新的邮件带有发票字眼时是垃圾邮件的概率是多少？

P(A1) = p(正常邮件) = 正常邮件的概率 = 300/400 = 0.75  
P(A2) = P(垃圾邮件) = 垃圾邮件的概率 = 100/400 = 0.25  
P(B) = P(发票) = 出现发票的概率 = 3/300 + 5/100 = 0.02  
P(B|A2) = P(发票|垃圾邮件) = 垃圾邮件中出现发票的概率 = 5/100 = 0.05  
P(B|A1) = P(发票|正常邮件) = 正常邮件中出现发票的概率 = 3/300 = 0.01  

求：P(A2|B) = P(垃圾邮件|发票) = 当出现发票时为垃圾邮件的概率  
> P(A2|B) = P(A2)P(B|A2)/P(B)   
>	= 0.25*0.05 / 0.02  
>	= 0.625  

问2：如何用贝叶斯公式做分类，当新的邮件过来时如何区分是否为垃圾邮件。

借助上一题的结论，我们可以通过单个单词去预测一封邮件是垃圾邮件的概率是多少。
同样的我们也可以通过多个单词去进行预测，这里引入连续条件概率的概念。
将文档中的单词进行分词，得出组成文档的所有单词然后进行条件概率计算。

设：X 为单词, D1为垃圾邮件, D2为正常邮件，再次代入贝叶斯公式
>P（A|B）= P(B|A)*P(A)/P(B)
P(D1|X1...Xn) = P(垃圾邮件|单词1...单词n) = P(垃圾邮件)*P(单词1|垃圾邮件)*...*P(单词n|垃圾邮件)/P(单词1...单词n)
P(D2|X1...Xn) = P(正常邮件|单词1...单词n) = P(垃圾邮件)*P(单词1|正常邮件)*...*P(单词n|正常邮件)/P(单词1...单词n)

以上两个公式各自算出是垃圾/正常邮件的概率，将两个概率进行大小对比，将邮件归类于大的一方。
在计算过程中我们发现他们的分母是一致的，这样我们只需计算他们的分子再比较大小就可以了。

补充：
然后有的聪明的同学就会发现：如果有些单词在样本里没出现过套进公式后不就等于0了么？

所以在这个算法基础上要对公式进行补充：引入拉普拉斯平滑项。
就是对每个类别下所有划分的计数加1，分母加上当前特征分类个数（2）。当采用词袋统计表示文本特征向量时，每个单词作为是作为单独的特征，而0,1代表出现过/未出现过这时分类个数为2。

we补充2：



